<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.2.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.2.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="原文 循环神经网络（Recurrent Neural Networks）思考问题时，人类不是每一时刻都是从零开始的。当你阅读这篇短文时，对于每一个词的理解都是基于这个词之前的词的含义。你不会把前面看到的丢弃，然后从零开始。你的思考是连贯的。 传统的神经网络无法做到这一点，并且这是它的一个主要的缺点。例如，假如你想清楚地知道在一个电影的每一个片段发生了什么样的事情。现在，还不能确定，传统的神经网络如">
<meta name="keywords" content="LSTM,Machine learning">
<meta property="og:type" content="article">
<meta property="og:title" content="深入理解LSTM（Understanding LSTM Networks）">
<meta property="og:url" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/index.html">
<meta property="og:site_name" content="小虎头 加油">
<meta property="og:description" content="原文 循环神经网络（Recurrent Neural Networks）思考问题时，人类不是每一时刻都是从零开始的。当你阅读这篇短文时，对于每一个词的理解都是基于这个词之前的词的含义。你不会把前面看到的丢弃，然后从零开始。你的思考是连贯的。 传统的神经网络无法做到这一点，并且这是它的一个主要的缺点。例如，假如你想清楚地知道在一个电影的每一个片段发生了什么样的事情。现在，还不能确定，传统的神经网络如">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/RNN-rolled.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/RNN-unrolled.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/RNN-shorttermdepdencies.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/RNN-longtermdependencies.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-SimpleRNN.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-chain.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM2-notation.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-C-line.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-gate.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-focus-f.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-focus-i.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-focus-C.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-focus-o.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-var-peepholes.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-var-tied.png">
<meta property="og:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/LSTM3-var-GRU.png">
<meta property="og:updated_time" content="2018-05-13T12:02:37.479Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深入理解LSTM（Understanding LSTM Networks）">
<meta name="twitter:description" content="原文 循环神经网络（Recurrent Neural Networks）思考问题时，人类不是每一时刻都是从零开始的。当你阅读这篇短文时，对于每一个词的理解都是基于这个词之前的词的含义。你不会把前面看到的丢弃，然后从零开始。你的思考是连贯的。 传统的神经网络无法做到这一点，并且这是它的一个主要的缺点。例如，假如你想清楚地知道在一个电影的每一个片段发生了什么样的事情。现在，还不能确定，传统的神经网络如">
<meta name="twitter:image" content="http://yoursite.com/2018/05/01/understanding-lstm-networks/RNN-rolled.png">






  <link rel="canonical" href="http://yoursite.com/2018/05/01/understanding-lstm-networks/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>深入理解LSTM（Understanding LSTM Networks） | 小虎头 加油</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">小虎头 加油</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">老兵不死，之渐凋零</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>




<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/01/understanding-lstm-networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiaohutou">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小虎头 加油">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深入理解LSTM（Understanding LSTM Networks）
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-05-01 20:26:00" itemprop="dateCreated datePublished" datetime="2018-05-01T20:26:00+09:00">2018-05-01</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-05-13 21:02:37" itemprop="dateModified" datetime="2018-05-13T21:02:37+09:00">2018-05-13</time>
              
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/05/01/understanding-lstm-networks/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count gitment-comments-count" data-xid="/2018/05/01/understanding-lstm-networks/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">原文</a>
<h1 id="循环神经网络（Recurrent-Neural-Networks）"><a href="#循环神经网络（Recurrent-Neural-Networks）" class="headerlink" title="循环神经网络（Recurrent Neural Networks）"></a>循环神经网络（Recurrent Neural Networks）</h1><p>思考问题时，人类不是每一时刻都是从零开始的。当你阅读这篇短文时，对于每一个词的理解都是基于这个词之前的词的含义。你不会把前面看到的丢弃，然后从零开始。你的思考是连贯的。</p>
<p>传统的神经网络无法做到这一点，并且这是它的一个主要的缺点。例如，假如你想清楚地知道在一个电影的每一个片段发生了什么样的事情。现在，还不能确定，传统的神经网络如何能够基于已知的事件推断出将要发生的事件。</p>
<p>循环神经网络致力于解决该问题。这样的网络通过环回链接，保持信息的连贯性。</p>

<img src="/2018/05/01/understanding-lstm-networks/RNN-rolled.png" width="100px" height="100px">
<p align="center">带环的循环神经网络 </p>


<p>在上图中，A是一个神经网络的一部分，输入$x_t$得到输出$h_t$。环回链接控制信息被从网络的一层传递到下一层。</p>
<p>这些环回链接使得循环神经网络看起来有些神秘。但是，如果你更进一步地思考，它与普通的神经网络没有太大的区别。一个循环神经网络可以被认为是一个网络的多个拷贝，每一个把信息传递给下一个。对循环神经网络做循环展开后，它就是下面的样子：</p>
<img src="/2018/05/01/understanding-lstm-networks/RNN-unrolled.png">

<p align="center">循环展开的循环神经网络 </p>

<p>这种链式的本质说明了循环神经网络本质上与序列和链表相关。它天生就是要应用到这样的数据上。</p>
<p>当然，它们也是这样被使用的。在过去的几年中，它们在一些领域，取得了难以置信的成功。这个名单很长，主要包括：语音识别、语言模型和图像自动标题等。如果你想深入了解这方面的讨论，请阅读Andrej Karpathy的精彩博文“<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks.</a>”。这些例子真的是很神奇。</p>
<p>基本上，这些成功的例子都是使用了“LSTMs”。LSTMs是一个特殊的循环神经网络。在很多方面，它都比标准模型做的要好。在循环神经网络的成功案例几乎都是使用它们实现的。本文将主要讨论这些LSTMs模型。</p>
<a id="more"></a>
<h1 id="长距离间的依赖关系（The-Problem-of-Long-Term-Dependencies）"><a href="#长距离间的依赖关系（The-Problem-of-Long-Term-Dependencies）" class="headerlink" title="长距离间的依赖关系（The Problem of Long-Term Dependencies）"></a>长距离间的依赖关系（The Problem of Long-Term Dependencies）</h1><p>RNNs最令人着迷的是，它也许能够将当前的任务与之前的信息联系起来。例如，通过视频以播放过的帧来理解当前的这一帧。如果RNNs能做到，它的作用是巨大的。RNNs能做到吗？在某些条件下是的。<br>有些时候，当前的任务是可以依据最近的信息推测出来的。例如，依据前面已经出现的词推测下一个词的语言模型。当我们推测“the clouds are in the sky，”这句话的最后一个词时，已经不需要其他的上下文了；非常明显这个词是“sky”。（译者：其他的词“mountain”）。在这种情况下，相关联的词汇间的距离很短，RNNs能够学习如何使用这些信息。</p>
<img src="/2018/05/01/understanding-lstm-networks/RNN-shorttermdepdencies.png">
<p>但是在某些情况下需要更多的上下文。例如预测这句话 - “I grew up in France… I speak fluent French.” - 的最后一个词。与目标词最近的相关信息表明这个词很可能指某个语言。但是如果把这个词缩小到某个具体的语言上，就需要与距离较远的France的上下文考虑到。<br>与目标点相关的信息与目标点之间的间隔非常的大，这是完全可能的。</p>
<p>不幸的是，随着距离的增加，RNNs就不能学习到这些关联信息。</p>
<img src="/2018/05/01/understanding-lstm-networks/RNN-longtermdependencies.png">
<p>在理论上，RNNs绝对能够处理长距离间的依赖关系。通过仔细挑选参数，能够在一些实验性的玩具项目上取得很好的效果。不幸的是，在现实中，RNNs不能学习使用这些信息。Hochreiter (1991) [German] 和 Bengio, et al. (1994), 在这方面做了深入的研究，他们的研究结果揭示了一些RNNs在这方面的本质上的缺陷。</p>
<p>令人欣慰的是，LSTMs能解决这个问题！</p>
<h1 id="LSTM网络"><a href="#LSTM网络" class="headerlink" title="LSTM网络"></a>LSTM网络</h1><p>长短期记忆网络 - 通常被称为“LSTMs” - 是一个特殊的RNN，能够学习使用长期的依赖关系。在1997年，Hochreiter &amp; Schmidhuber首次提出了这个模型。随后，很多人（Felix Gers, Fred Cummins, Santiago Fernandez, Justin Bayer, Daan Wierstra, Julian Togelius, Faustino Gomez, Matteo Gagliolo, and Alex Graves）对该模型进行了优化，并使其流行起来。LSTM网络能够很好地解决很多问题，因此现在被广泛使用。</p>
<p>LSTMs致力于解决长期依赖关系的问题。记忆一段时间内的信息是LSTMs固有的功能，而不是挣扎地调优的参数。</p>
<p>所有的循环神经网络都是一个重复模块链的结构。在标准的RNNs中，这个重复的模块的结构非常的简单，例如一个单独的tanh层。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-SimpleRNN.png">

<p align="center">The repeating module in a standard RNN contains a single layer. </p>

<p>LSTMs当然也是这种链式结构，但是重复模块有不同的结构。LSTMs有四个网络层，而不是一个，这四个网络层以一种特殊的方式交互。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-chain.png" title="The repeating module in an LSTM contains four interacting layers.">
<p>暂时不要纠结它们是如何工作的。本文会逐步帮助你理解它们。现在，让我们先熟悉一些将要使用的术语。<br><img src="/2018/05/01/understanding-lstm-networks/LSTM2-notation.png"><br>在上图中，每个图标操作一个向量，粉红色的圆圈代表点乘操作，类似向量加法。黄色的方块表示神经网络层。合并箭头表示连接操作。分叉的箭头表示数据被拷贝到不同的地方。</p>
<h1 id="LSTMs的核心思想"><a href="#LSTMs的核心思想" class="headerlink" title="LSTMs的核心思想"></a>LSTMs的核心思想</h1><p>LSTMs的核心是神经元的状态，如下图中最上面的水平线所示，其状态从$C_{t-1}$变换到$C_t$。<br>神经元的状态类似一种传送带。它直线穿过整个数据链，在这个过程中只有一些线性交互。所以，在这个过程中信息可能没有任何的变化。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-C-line.png">
<p>LSTM的门有计划、有组织地在神经元上删除或添加信息。门选择性地允许信息从数据链上通过。它由一个sigmod神经网络层和点乘操作组成。</p>

<img src="/2018/05/01/understanding-lstm-networks/LSTM3-gate.png" width="100px" height="100px">

<p>sigmod神经网络层的输出介于0和1之间，表示允许多少信息通过。其值为零时，则不允许任何信息通过；为1时，则全部放行。</p>
<h1 id="LSTM步骤分解"><a href="#LSTM步骤分解" class="headerlink" title="LSTM步骤分解"></a>LSTM步骤分解</h1><p>LSTM网络首先选择从神经元中移除哪些信息。这个操作由一个sigmod层，也被称为“失忆门”层，来决定的。它的输入时$h_{t_1}$和$x_t$，输出一个介于0和1之间的数值，这个数值将被应用到每一个神经元的$C_{t-1}$上。当值为1时，意味着$C_{t-1}$全部保留；值为0，则与之相反，$C_{t-1}$全部被丢弃。</p>
<p>现在，让我们回想一下预测下一单词的例子。在这类问题上，神经元的状态也许包含了已知的主语词性，因此，可以推断出正确的代词。当遇到一个新的主语时，期望能够去掉已知的主语词性。<br><div class="note "><p>译者:<br>最初将subject一词理解为单词，但阅读到后面时，发现基于language model一词，这里应该是指一句话中的“主语”。</p></div></p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-focus-f.png">
<p>下一步是确定在神经元中存储哪些信息。这包含两个过程。首先，一个sigmoid层，也被称为“输入门层”决定更新哪些值。然后，一个tanh层创建一个新的候选值向量， $C_t$，它们能够被加入到神经元中。接下来，使用这些值合成一个新的状态。</p>
<p>在前面提到的预测单词的语言模型例子中，期望在神经元中使用新的主语词性替换旧的。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-focus-i.png">
<p>接下来的任务，就是把神经元的状态从$C_{t-1}$迁移到$C_t$。到了这里，已经知道了做什么，现在只需要计算出新的状态。</p>
<p>神经元的已知状态乘以$f_t$，。然后，将结果与$i_t * \widetilde{C_t}$ 的结果相加。至此，得到新的状态值，其与需要更新的信息多少成正比。</p>
<p>在单词预测的语言模型中，这一步丢弃了已知的主语词性信息，并添加了新的信息。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-focus-C.png">
<p>最后一步的工作是输出结果。输出结果是基于被过滤过的神经元状态的。首先，一个sigmoid层确定神经元状态的哪些部分被输出。然后，神经元的状态被归一化处理（tanh层）并与sigmoid门的输出相乘。至此，得到想要的输出。</p>
<p>在单词预测的语言模型中，但其遇到一个主语时，它期望输出与动词相关的信息，通常，主语后面是动词。例如，输出的主语可能是单数或多数，就知道接下来该使用动词的词格。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-focus-o.png">
<h1 id="Variants-on-Long-Short-Term-Memory"><a href="#Variants-on-Long-Short-Term-Memory" class="headerlink" title="Variants on Long Short Term Memory"></a>Variants on Long Short Term Memory</h1><p>至此，本文详细阐述了一个通用的LSTM模型。但是，并不是所有的LSTMs都和本文描述的一样。事实上，几乎每篇论文涉及LSTMs的论文中使用的模型都在细节上有所不同。尽管这些不同是微小的，但是有些还是值得探讨一下。</p>
<p>一个最为常用的LSTM变体，是Gers &amp; Schmidhuber在2000年提出的，“peephole connections”。其允许门层看到神经元状态。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-var-peepholes.png">
<p>在上图中，在所有的门中添加了“peepholes”，但是很多的论文中只在部分门中添加“peepholes”。</p>
<p>另一个变体是把失忆门和输入门组合在一起。即，同时处理丢弃和添加信息，而不是分开来做。在该模型中，只有有输入信息时才丢弃信息。只有在丢弃信息是，才有新的信息输入。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-var-tied.png">
<p>Cho，et al. 在2014年引入了门循环单元（ Gated Recurrent Unit, or GRU）。它将忘记门和输入门合成为一个“更新门”（“update gate”）。同时，它把神经元层和隐藏层合并到一起，以及一些其他的改变。该模型比标准的LSTM模型简单，并且很快流行起来。</p>
<img src="/2018/05/01/understanding-lstm-networks/LSTM3-var-GRU.png">
<p>以上只是几个非常值得注意的LSTM变体。LSTMs的变体非常的多，如Depth Gated RNNs by Yao, et al. (2015)。当然，还有一些完全不同的处理长期依赖关系的方法，例如 Clockwork RNNs by Koutnik, et al. (2014).</p>
<p>哪个LSTM变体最好？这些变化发挥了多大的作用？Greff, et al. (2015)对这些变体做了比较，发现它们几乎差不多。Jozefowicz, et al. (2015)测试了成千上万的RNN模型，发现在某些特定的任务上，有些比LSTM的效果好。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文已经提到过使用RNNs所取得的显著成果。这些成果大都是通过LSTMs得到的。它们确实胜任很多任务。</p>
<p>由一组公式描述的LSTMs看起非常的恐怖。期望，本文分步骤地解析LSTM能够帮助你更好地理解。</p>
<p>LSTMs是一个巨大的飞跃在RNNs领域。您也许会问：有没有另一个巨大的飞跃？研究领域的观点是：“是的！下一个巨大的飞跃就是attention。”Attention网络的核心是在RNN的每一个步骤中，从一个大的数据集中提取信息。例如，如果你想使用RNN来描述一张图片，可以从图片中截取一部分然后从其输出的单词中选择。事实上，Xu, et al. (2015) - 如果你想研究Attention网络，这是一个很好的起点。现在，Attension网络在很多方面取得了令人振奋的结果，并且还有很多值得去发掘的领域。</p>
<p>在RNN研究领域，Attention网络不是唯一令人振奋的。例如，Kalchbrenner, et al. (2015) 提出的Grid LSTMs看起来也非常有前景。在生殖模型中使用RNNs - 例如， Gregor, et al. (2015), Chung, et al. (2015), or Bayer &amp; Osendorfer (2015) - 也看起来很美。在过去的几年中，循环神经网络得到了飞速的发展。在接下来的时间里，会带来更多的惊喜。</p>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/LSTM/" rel="tag"># LSTM</a>
          
            <a href="/tags/Machine-learning/" rel="tag"># Machine learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/22/ovs-conntrack-tutorial/" rel="next" title="OpenvSwitch的链接追踪教程">
                <i class="fa fa-chevron-left"></i> OpenvSwitch的链接追踪教程
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/13/ubuntu16-libvirt-call-ovsvsctl-denied/" rel="prev" title="ubuntu16.04 下libvirtd调用ovs-vsctl被apparmor拒绝">
                ubuntu16.04 下libvirtd调用ovs-vsctl被apparmor拒绝 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">xiaohutou</p>
              <p class="site-description motion-element" itemprop="description">有志 有识 有恒</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">9</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#循环神经网络（Recurrent-Neural-Networks）"><span class="nav-number">1.</span> <span class="nav-text">循环神经网络（Recurrent Neural Networks）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#长距离间的依赖关系（The-Problem-of-Long-Term-Dependencies）"><span class="nav-number">2.</span> <span class="nav-text">长距离间的依赖关系（The Problem of Long-Term Dependencies）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LSTM网络"><span class="nav-number">3.</span> <span class="nav-text">LSTM网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LSTMs的核心思想"><span class="nav-number">4.</span> <span class="nav-text">LSTMs的核心思想</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LSTM步骤分解"><span class="nav-number">5.</span> <span class="nav-text">LSTM步骤分解</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Variants-on-Long-Short-Term-Memory"><span class="nav-number">6.</span> <span class="nav-text">Variants on Long Short Term Memory</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-number">7.</span> <span class="nav-text">总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiaohutou</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动 v3.7.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Gemini</a> v6.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.2.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.2.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.2.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.2.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.2.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.2.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.2.0"></script>



  



	





  





  






<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    
      <script type="text/javascript">
      function renderGitment(){
        var gitment = new Gitmint({
            id: window.location.pathname,
            owner: 'xiaohutou',
            repo: 'xiaohutou.github.io',
            
            lang: "" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: '67f5892dc03fd6d49a5c95713a520d93077da765',
            
                client_id: '649abcb8a6b6f2bbc68b'
            }});
        gitment.render('gitment-container');
      }

      
      renderGitment();
      
      </script>
    






  





  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

</body>
</html>
